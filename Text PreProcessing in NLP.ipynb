{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f43436-d9f7-4951-bee4-66a8b0cad793",
   "metadata": {},
   "source": [
    "<h1>Text Preprocessing in NLP</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff85ea9-f232-47db-b3f3-896292e6f0dc",
   "metadata": {},
   "source": [
    "<p>Text preprocessing is a necessary and important step in Natural Language Processing, as raw text data is often inconsistent and not efficient to recognize for the system. Proper preprocessing improves the models accuracy via methods of reducing variation (lowercasing, lemmatization, stemming), reducing time complexity and space complexity, handling text inconssistencies (this may include slang terms, abbrevations and emojis), reduces overfitting and are essential for multilingual NLP's (Japanese and Chinese do not contain white spaces, making words hard to understand). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc7011-d474-4fd8-81ab-03070850ae62",
   "metadata": {},
   "source": [
    "<h2>Regular Expressions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf632a5-2d8f-4c83-8aca-38cfe0d3de89",
   "metadata": {},
   "source": [
    "<p>Regular expressions are patterns used to match character combinations in strings. These allow efficient pattern matching and text manipulation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94ae460-f3df-43ed-acad-b4f19e91cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Finding '@' in a message and the tag it is refering to.\n",
    "import re\n",
    "\n",
    "String = \"You would not believe what @lorem and @ipsum said to the @fox\"\n",
    "tags = re.findall(r\"@\\w+\", String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809bf642-f359-4983-97f0-ca4fbfb486d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@lorem', '@ipsum', '@fox']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac079ff-8ce9-4125-b6c4-360659abac00",
   "metadata": {},
   "source": [
    "<h2>Tokenization</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819b9a8-b2dc-4ddb-8903-b0be2c06f92c",
   "metadata": {},
   "source": [
    "<p>Tokenization is the process of breaking down a given text, into fragments called token. These tokens helps computers understand and process human language by splitting it into manageable units. Multiple tokenization algorithms exist each with their pros and cons.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37584b92-c0b8-4fe1-829f-520c4d42fa24",
   "metadata": {},
   "source": [
    "<h2>Lemmatization and stemming</h2><br>\n",
    "<p>Lemmatization is the process of reducing words to their root form, while ensuring that the transformed word is still a valid word in the dictionary. Lemmatization model is widely used in Search Engines, Chatbots and Text Summarization</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9ca4c7-b1ae-48ec-af81-d8d69c15557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understanding\n",
      "understand\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(lemmatizer.lemmatize(\"understanding\")) # the model considers the string as a noun\n",
    "print(lemmatizer.lemmatize(\"understanding\", pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9628930f-045f-4090-a0ff-0610c85b47fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swimming\n",
      "swim\n",
      "pastry\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "#some other examples\n",
    "print(lemmatizer.lemmatize(\"swimming\", pos=\"n\"))\n",
    "print(lemmatizer.lemmatize(\"swimming\", pos=\"v\"))\n",
    "print(lemmatizer.lemmatize(\"pastries\", pos=\"n\"))    \n",
    "print(lemmatizer.lemmatize(\"great\", pos=\"a\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf05e88-070c-4f4b-bddf-8c8427273444",
   "metadata": {},
   "source": [
    "<p>Stemming reduces words to their base form if it ends with a given set of characters. Unlike Stemming, the word formed may not necessarily need to be a valid word. Stemming errors at times may be ignored, especially in LLM's as they rely on tokenization and embeddings rather than raw word forms. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de190e03-a22f-4583-a5ef-d029f5e37fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running:run\n",
      "sees:see\n",
      "batter:batter\n",
      "better:better\n",
      "betterment:better\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import random\n",
    "\n",
    "words = [\"running\", \"sees\", \"batter\", \"better\", \"betterment\"]\n",
    "\n",
    "for i in words:\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_word = stemmer.stem(i)\n",
    "    print(f\"{i}:{stemmed_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35eb899-dd31-4201-a88e-d6560a846bcf",
   "metadata": {},
   "source": [
    "<h2>Parts Of Speech (POS)</h2>\n",
    "<p>POS assigns each word in the text a given label (ex. noun, adjective) based on its role in the sentence.It allows algorithms to understand the grammatical structure of a sentence and to disambiguate words that have multiple meanings.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91b5a0d7-f2ae-4d7c-a1f5-a3776caa1a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#Heres an example of POS\n",
    "from textblob import TextBlob\n",
    "\n",
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "blob = TextBlob(sentence)\n",
    "\n",
    "print(blob.tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
